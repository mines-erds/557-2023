{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"provenance":[{"file_id":"https://github.com/agile-geoscience/xlines/blob/master/notebooks/12_Ternary_diagrams.ipynb","timestamp":1597425402261}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"HG8HVu_fRSiX"},"source":["# Module 4: Data viz\n","\n","## Overview: Geospatial data viz\n","This notebook will take you through python code very commonly used to import, sort, and visualize some data, in this case a spreadsheet of USGS core data. We will use `pandas` and several packages for geospatial map-making, including `geopandas`, `folium`, and `plotly`.\n","\n","For questions on this notebook, ask them on the [GEOL 557 slack](https://join.slack.com/t/minesgeo/shared_invite/zt-cqawm4lu-Zcfpf4mBLwjnksY6_umlKA)<a href=\"https://join.slack.com/t/minesgeo/shared_invite/zt-cqawm4lu-Zcfpf4mBLwjnksY6_umlKA\">\n","<img src=\"https://cdn.brandfolder.io/5H442O3W/as/pl546j-7le8zk-ex8w65/Slack_RGB.svg\" alt=\"Go to the GEOl 557 slack\" width=\"100\">\n","</a>\n","\n","## Instructions\n","Work through this notebook - there will be several places where you need to fill-in-the-blank or write some code into an open cell. When you are finished, make sure to use the Colab menu (not the browser-level menu) to do the following:\n","- Expand all the sections - in the Colab menu, choose View --> Expand sections) \n","- Save the notebook as a pdf, again using the Colab menu, using File --> Print --> Save as PDF. \n","\n","--- \n","## Course\n","**GEOL 557 Earth Resource Data Science I: Fundamentals**. GEOL 557 forms part 2 of the four-part course series for the \"Earth Resource Data Science\" online graduate certificate at Mines - [learn more about the certificate here](https://online.mines.edu/er/)\n","\n","Notebook created by **Zane Jobe** and **Thomas Martin**, [CoRE research group](https://core.mines.edu), Colorado School of Mines\n","\n","[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/ZaneJobe.svg?style=social&label=Follow%20%40ZaneJobe)](https://twitter.com/ZaneJobe)\n","and [![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/ThomasM_geo.svg?style=social&label=Follow%20%40ThomasM_geo)](https://twitter.com/ThomasM_geo) on Twitter  \n","\n","-------------------\n","# OK, let's do some coding!\n","## First, let's import some packages and install some stuff"]},{"cell_type":"code","metadata":{"id":"caob4Ux1syVZ"},"source":["## THIS WILL TAKE ABOUT TWO MINUTES TO RUN...\n","\n","# install stuff\n","!pip install geopandas\n","!pip install earthpy\n","# !pip install plotly==4.10.0 # needs to be this latest version (Sept 2020), as Colab has an older version as the default\n","!pip install plotly --upgrade\n","\n","# import stuff\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","import geopandas as gpd\n","import earthpy as et\n","\n","import folium\n","\n","import plotly.express as px"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qv393_x-RLyG"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JEoyerAOPjDj"},"source":["## Import some data\n","We will use a csv file that has lists all the cores in the USGS Core Research Center in Lakewood, CO. I just downloaded it directly from the website and made no changes to it. That's the whole point of all this, which is to work with data you can easily obtain and not spend time manually changing things in Excel. \n","\n","You don't need to do this, but if you want to recreate this dataset, you can download this exact spreadsheet from the [USGS CRC](https://my.usgs.gov/crcwc/). Just click search, don't type anything into the boxes. You should get 16,531 rows (as of Feb 2020), which you can export as a CSV at the bottom of the page. You could do the same things for cuttings by clicking on the cuttings tab (there are 53,456 rows in the cuttings database), but we will just stick with cores for now - 16,000 rows is plenty of data for our first foray into python!\n","\n","If the code to import the data does not work, you can go to [this csv](https://docs.google.com/spreadsheets/d/1fX8ZyF2Pmx7apcBftvWVVOUlPTCRl014cIASIowAVNE/edit?usp=sharing) in Google Drive - open it in Google Sheets, and then click 'Share' in the upper right hand corner. Copy the link, and then paste it below, replacing the `view?usp=sharing` with `export?format=csv`.\n","\n","BTW - if instead you go to the file straight in Google Drive, and copy the link from there rather than inside of Google Sheets, you need to do the import a slightly different way (described in this [stackoverflow post](https://stackoverflow.com/questions/56611698/pandas-how-to-read-csv-file-from-google-drive-public)). Why it is different in Sheets vs, Drive, I do not know..."]},{"cell_type":"code","metadata":{"id":"zK41qsdvO-A2"},"source":["from google.colab import drive # this mounts Google Drive to this notebook\n","drive.mount('/content/gdrive')\n","\n","# these next two things shuoldnt need to be changed if you set up your Google Drive folder correctly (see Module 1)\n","folder_path = 'gdrive/My Drive/GEOL557_F22/data/' # makes a path\n","file_name = 'USGS_cores_all.csv' # file name\n","\n","df=pd.read_csv(folder_path + file_name) # uses pandas to read in the csv as a 'DataFrame' called df\n","\n","df.head(2) # show the first two lines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVrzYlpkZYWo"},"source":["## Check out what is in the `DataFrame` we just made"]},{"cell_type":"code","metadata":{"id":"amOadD_6ZTgw"},"source":["df.info() # this lists all of the column names and their attributes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0dJLUCIu3Qb"},"source":["# now let's make a thickness value from the Depth columns, and then add it to the DataFrame\n","\n","th=df['Max Depth']-df['Min Depth'] # make the variable\n","df['Thickness']=th                 # assign it to a new column in dataframe called thickness\n","df.Thickness.describe()            # get some stats"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6zsvTAd7vNPb"},"source":["A median of 41 feet per well seems ok, but the mean is 126, so the distribution is extremely log-normal. Notice the max and min are obviously errors in the database. We won't worry about that for now, as we want to check out the bulk statistics of the database. But good to know there may be a few weird values that you would want to filter out. \n","\n","Also, note that there are a few thickness values missing, as the dataframe is 16531 rows and the thickness only has 16485 rows (meaning some rows don't have depth values)."]},{"cell_type":"code","metadata":{"id":"sU0o4BOgvkmo"},"source":["original_length = len(df)\n","\n","df = df[df.Thickness>0]            # get rid of negative values\n","df = df[df.Thickness<1000]         # get rid of huge values\n","\n","dropped = original_length - len(df)\n","\n","print(str(dropped)+' values dropped out of '+str(original_length)+' values')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qgUCuzcS4Moq"},"source":["## Now let's make some simple plots"]},{"cell_type":"code","metadata":{"id":"n45Zsay49Q5t"},"source":["df.plot(kind='scatter', x='Longitude', y='Latitude')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ps3EKHviH6Yx"},"source":["Can you see the Alaska cores?\n","\n","Also looks like there are some values over in Fiji, but we wont worry about those for now. \n","\n","Instead, let's clip Alaska out of the plot and make a bubble plot of core thickness"]},{"cell_type":"code","metadata":{"id":"PhpT9NDQ8w5-"},"source":["plt.scatter(df.Longitude,df.Latitude, s=df.Thickness/50)\n","plt.xlim([-120, -90])\n","plt.ylim([30, 50]);\n","\n","# Can you see the Rockies? This is starting to look like the US, \n","# but we can do so much better, as you will see below"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZapLlF1l9l6J"},"source":["### But before we go onto making fancier maps, let's make some bar charts!"]},{"cell_type":"code","metadata":{"id":"U7EW__JU38JP"},"source":["fm_counts=df['Formation'].value_counts() # get value counts of all the formations\n","\n","sns.barplot(y=fm_counts.index[0:20], \n","            x=fm_counts.values[0:20])    # plot it\n","plt.title('Top 20 Formations with the most cores');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tF-XE9R4ST6"},"source":["# Show what types of data are in Colorado\n","co=df.loc[df['State']=='CO']\n","co_counts=co['Type'].value_counts()\n","sns.barplot(y=co_counts.index, x=co_counts.values)\n","plt.title('Types of core data in Colorado');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QqL6QH3Q8XLM"},"source":["## Now you try to make a simple plot\n","Pick anything! Perhaps a KDE of core thickness from a particular state? Howver, don't fool with lat-long for now, we will spend plenty of time on that below..."]},{"cell_type":"code","metadata":{"id":"vNi9Q6DPRmYV"},"source":["df.State.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdaEOeq38TT2"},"source":["# your code here\n","UT=df.loc[df['State']=='UT']\n","UT_counts=UT['Age'].value_counts()\n","sns.barplot(y=UT_counts.index, x=UT_counts.values)\n","plt.title('Geological ages in Utah');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vL1MNeblSznr"},"source":["df.Field.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnIDwzUeSfd9"},"source":["WI=df.loc[df['Field']=='WILDCAT']\n","WI_counts=WI['Type'].value_counts()\n","sns.barplot(y=WI_counts.index, x=WI_counts.values)\n","plt.title('Type of core presented  in Wildcat Field');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WuCTQfRUXhU"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qm1zRjv8VA3n"},"source":["df.Thickness.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezEttmEMVR9d"},"source":["plt.figure(figsize=(14,10))\n","plt.scatter(x='Longitude', y='Latitude', data = df, c='Thickness', vmin=0, vmax=150 )\n","plt.xlim(-120,-90)\n","plt.ylim(30,50)\n","plt.ylabel('Latitude', fontsize=12)\n","plt.xlabel('Longitude')\n","plt.title('Cores by lattitude - Color-code Thickness')\n","plt.colorbar(label='Thickness')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7L-xkWE6OfLP"},"source":["# Basic maps using geopandas\n","\n","We will use two methods to retrieve data from the internet:\n","1. geojson files using geopandas\n","  - `geojson` files are pretty nicely formatted text files. More on that format at [geojson.org](https://geojson.org). An example of creating a geojson file from a pandas DataFrame is shown in a nice notebook [here](https://github.com/gboeing/urban-data-science/blob/master/17-Leaflet-Web-Mapping/leaflet-simple-demo/pandas-to-geojson.ipynb). \n","\n","2. zip files using Earthpy and geopandas\n","  -  Earthpy unzips and stores data on our Colab 'computer'. The one-liners below look complicated, but basically just unzip a file downloaded from the internet and turn it into a GeoDataFrame. For some reason, the zip files won't work in Colab for NaturalEarthData, hence the #1 method above...\n"]},{"cell_type":"code","metadata":{"id":"yPQOPoGu_8-1"},"source":["# get basic geopandas data\n","world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n","\n","'''\n","get county data for the US from this website\n","https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n","\n","We will do this with Earthpy, which takes the zip file, stores it in Colab, and then unzips it and feeds it to geopandas\n","'''\n","\n","counties = gpd.read_file(\n","    et.data.get_data(\n","        url=\n","        'https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_500k.zip'\n","        )\n","    )\n","\n","'''\n","Now Let's get some custom data from the EIA\n","I got the data from this website https://www.eia.gov/maps/maps.htm, and here is a summary map: https://www.eia.gov/maps/images/shale_gas_lower48.jpg\n","'''\n","\n","plays = gpd.read_file(\n","    et.data.get_data(\n","        url=\n","        'https://www.eia.gov/maps/map_data/TightOil_ShaleGas_Plays_Lower48_EIA.zip'\n","        )\n","    )\n","\n","basins = gpd.read_file(\n","    et.data.get_data(\n","        url=\n","        'https://www.eia.gov/maps/map_data/SedimentaryBasins_US_EIA.zip'\n","        )\n","    )\n","\n","'''\n","get NaturalEarthdata\n","the links below copied from https://github.com/nvkelso/natural-earth-vector/tree/master/geojson\n","but you can also go to this site https://www.naturalearthdata.com/downloads/\n","\n","For some weird reason, Colab doesnt like Earthpy .zip files for these (see below for an example), so \n","we will be using the geojson files directly from Github instead...\n","'''\n","coastlines = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_50m_coastline.geojson')\n","\n","countries = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_50m_admin_0_boundary_lines_land.geojson')\n","\n","rivers = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_10m_rivers_lake_centerlines.geojson')\n","\n","states = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_110m_admin_1_states_provinces.geojson')\n","\n","cities = gpd.read_file('https://github.com/nvkelso/natural-earth-vector/raw/master/geojson/ne_10m_populated_places.geojson')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R0dILPA-_AEs"},"source":["Isn't that handy!? You can see where Earthpy put those files, each of which is a zip file consisting of a `.shp` and its brethren. Instead of doing this, you could also:\n","\n","- Download the files\n","- click on the little folder icon on the left-hand sidebar\n","- click the little up-arrow button, and select the zip file and upload them\n","- then right-click on that file and copy the path and use it to read directly into geopandas using gpd.read_file('filename.shp')\n","\n","## Let's take a look at some of the data\n","Each one of these variables is a `GeoDataFrame`, which is basicallt a pandas DataFrame with a `geometry` column. Read more about geometries [in the geopandas docs.](https://geopandas.org/data_structures.html)"]},{"cell_type":"code","metadata":{"id":"o75cawFaN7pT"},"source":["print(type(basins))\n","basins.head(3) # what does basins look like?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHD5y3WZ_9BN"},"source":["# Let's make a simple figure\n","\n","fig, ax = plt.subplots(figsize=[15,15])\n","world.boundary.plot(ax=ax,color='k') #the boundary method only plots the outlines with no fill\n","rivers.plot(ax=ax,color='b',linewidth=0.5)\n","ax.set_aspect('equal')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_BTQwSy1SmHC"},"source":["It would be nice to be able to label these countries or cities. We will use pandas-style subsetting and a `lambda` to do this, this specific lamdba I [found here](https://github.com/shotleft/how-to-python/blob/master/How%20it%20works%20-%20labelling%20districts%20in%20GeoPandas.ipynb)). "]},{"cell_type":"code","metadata":{"id":"cvo7flRLeUb3"},"source":["world.continent.unique() # what continents do we have?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pB6gPG3v_9GJ"},"source":["# Let's subset the data, then plot it\n","\n","#only south america\n","south_america = world[world.continent=='South America']\n","africa = world[world.continent=='Africa']\n","\n","#plot\n","fig, axs = plt.subplots(1,2,figsize=[10,5])\n","south_america.plot(ax=axs[0],color='whitesmoke', edgecolor='k',linewidth=0.5)\n","africa.plot(ax=axs[1],color='whitesmoke', edgecolor='k',linewidth=0.5)\n","\n","#labels using a lambda\n","south_america.apply(lambda x: axs[0].annotate(s=x['name'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n","\n","# instead of the lambda, you can also loop it like this:\n","for x, y, label in zip(africa.centroid.x, \n","                       africa.centroid.y, \n","                       africa.name):\n","    axs[1].text(x, y, label, fontsize = 6, color='k', ha='center')\n","\n","for ax in axs: ax.set_aspect('equal')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qAfILwYAMDpF"},"source":["### Now you try\n","Make a map using the GeoDataFrames that are imported above - see if you can make a map and label things using Geopandas. Maybe one state and it's cities? Or basins and plays? "]},{"cell_type":"code","metadata":{"id":"hPzptQWHMDwu"},"source":["# your code here\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IM9LS7gScRcB"},"source":["\n","#only US\n","US = states[states.iso_a2=='US']\n","\n","#plot\n","fig, axs = plt.subplots(figsize=[10,15])\n","US.plot(ax=axs,color='whitesmoke', linewidth=0.35)\n","plt.xlim(-130,-60)\n","plt.ylim(20,50)\n","plt.title('US and States')\n","#labels using a lambda\n","US.apply(lambda x: axs.annotate(s=x['name'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n","\n","ax.set_aspect('equal')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfynN8fga9kE"},"source":["### Now let's look at EIA 'oil shale basins':"]},{"cell_type":"code","metadata":{"id":"Se26y67w_9PN"},"source":["fig, ax = plt.subplots(figsize=[15,15])\n","\n","basins.plot(ax=ax,facecolor='xkcd:blue', alpha=0.2, edgecolor='none') # shade\n","basins.plot(ax=ax,facecolor='none', edgecolor='xkcd:blue', linewidth=2) # outlines\n","states.plot(ax=ax,facecolor='none',edgecolor='k',linewidth=1)\n","\n","ax.scatter(df.Longitude, df.Latitude, s=1, facecolors='none', edgecolors='xkcd:orange')\n","\n","basins.apply(lambda x: ax.annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n","\n","ax.set_xlim([-130,-65])\n","ax.set_ylim([24,50])\n","ax.set_aspect('equal');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_mZTfdk6R3bq"},"source":["Looks a bit stretched - this has to do with the coordinate reference system - these are in a geographic coordinate system (WGS84), and we are used to looking at things in Mercator projection are projected in WGS84, but we are used to looking at things in Spherical Mercator, which is a projected coordinate system. Here is a [good intro](https://jcutrer.com/python/learn-geopandas-plotting-usmaps) to this issue. \n","\n","Let's take a look at the CRS:"]},{"cell_type":"code","metadata":{"id":"34sVfT1oSagU"},"source":["basins.crs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mcKVQ6mRS4_i"},"source":["# Let's also take our original dataframe and make it a geopandas\n","\n","# geographic coordinate system\n","wgs84 = 'EPSG:4326'\n","\n","df_geo = gpd.GeoDataFrame(df, crs=wgs84, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n","\n","# projected coordinate systems \n","albers_equal_area = 'EPSG:2163' # good for North America, terrible for other places\n","google_maps = 'EPSG:3857' # a modified mercator projection used in Google Maps\n","\n","# make into a projected coordinate system\n","df_geo = df_geo.to_crs(albers_equal_area)\n","df_geo.crs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNZU6B_qNXcU"},"source":["fig, ax = plt.subplots(figsize=[15,15])\n","\n","basins_proj = basins.to_crs(albers_equal_area)\n","states_proj = states.to_crs(albers_equal_area)\n","\n","# only the Lower 48 one-liner\n","states_proj.drop(states_proj[states_proj.name.isin(['Alaska','Hawaii'])].index, inplace=True) \n","\n","basins_proj.plot(ax=ax,facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n","basins_proj.plot(ax=ax,facecolor='none', edgecolor='xkcd:blue green') # outlines\n","states_proj.plot(ax=ax,facecolor='none',edgecolor='k',linewidth=1)\n","\n","df_geo.plot(ax=ax,color='xkcd:orange',markersize=1)\n","\n","basins_proj.apply(lambda x: ax.annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n","\n","xlim = ([states_proj.total_bounds[0],  states_proj.total_bounds[2]])\n","ylim = ([states_proj.total_bounds[1],  states_proj.total_bounds[3]])\n","\n","ax.set_xlim(xlim)\n","ax.set_ylim(ylim)\n","ax.set_aspect('equal');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-bSC4VA2TmzZ"},"source":["# compare two projections\n","\n","fig, axs = plt.subplots(1,2,figsize=[20,10])\n","\n","# EQUAL AREA\n","basins_proj.plot(ax=axs[0],facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n","basins_proj.plot(ax=axs[0],facecolor='none', edgecolor='xkcd:blue green') # outlines\n","states_proj.plot(ax=axs[0],facecolor='none',edgecolor='k',linewidth=1)\n","df_geo.plot(ax=axs[0],color='xkcd:orange',markersize=1)\n","basins_proj.apply(lambda x: axs[0].annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n","xlim = ([states_proj.total_bounds[0],  states_proj.total_bounds[2]]); ylim = ([states_proj.total_bounds[1],  states_proj.total_bounds[3]])\n","axs[0].set_xlim(xlim); axs[0].set_ylim(ylim); axs[0].set_aspect('equal');\n","\n","# GOOGLE MAPS Psuedo Mercator\n","basins_proj = basins.to_crs(google_maps)\n","states_proj = states_proj.to_crs(google_maps)\n","df_geo = df_geo.to_crs(google_maps)\n","\n","basins_proj.plot(ax=axs[1],facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n","basins_proj.plot(ax=axs[1],facecolor='none', edgecolor='xkcd:blue green') # outlines\n","states_proj.plot(ax=axs[1],facecolor='none',edgecolor='k',linewidth=1)\n","df_geo.plot(ax=axs[1],color='xkcd:orange',markersize=1)\n","basins_proj.apply(lambda x: axs[1].annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0], ha='center',fontsize=8,color='black'),axis=1);\n","xlim = ([states_proj.total_bounds[0],  states_proj.total_bounds[2]]); ylim = ([states_proj.total_bounds[1],  states_proj.total_bounds[3]])\n","axs[1].set_xlim(xlim); axs[1].set_ylim(ylim); axs[1].set_aspect('equal');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZX3bg1e_9Rf"},"source":["# now just the Powder River Basin\n","cities_sub = cities.to_crs(google_maps)[cities.ADM1NAME=='Wyoming']\n","df_geo_sub = df_geo[df_geo.State=='WY']\n","\n","fig, ax = plt.subplots(figsize=[10,10])\n","\n","basins_proj[basins_proj.NAME=='POWDER RIVER'].plot(ax=ax,facecolor='xkcd:blue green', alpha=0.2, edgecolor='none') # shade\n","basins_proj[basins_proj.NAME=='POWDER RIVER'].plot(ax=ax,facecolor='none', edgecolor='xkcd:blue green') # outlines\n","states_proj[states_proj.name=='Wyoming'].plot(ax=ax,facecolor='none',edgecolor='k',linewidth=2)\n","states_proj[states_proj.name=='Montana'].plot(ax=ax,facecolor='none',edgecolor='k',linewidth=2)\n","\n","cities_sub.plot(ax=ax,color='k',markersize=20)\n","\n","df_geo_sub[df_geo_sub.Formation=='PARKMAN'].plot(ax=ax,color='xkcd:orange',markersize=5)\n","\n","cities_sub.apply(lambda x: ax.annotate(s=x['NAME'], xy=x.geometry.centroid.coords[0],ha='right',fontsize=8,color='black'),axis=1);\n","\n","ax.set_aspect('equal')\n","plt.tight_layout();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZSLTi0v7Qqyo"},"source":["So, that looks pretty good, but it's pretty basic, and you see that you have to tell geopandas exactly what to do, and you have to label everything manually. There are better ways, which we will see below - but first...\n","\n","### Your turn!\n","\n","Pick another basin and formation, and make another map!"]},{"cell_type":"code","metadata":{"id":"odHMPSQBQoIx"},"source":["### your code goes here\n","# figure out a basin and formation using pandas\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOVozvVcRnDY"},"source":["# Now plot it using geopandas!\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ueXbBps7P3lo"},"source":["## Folium web-mapping\n","Folium is a pretty cool package in python that allows you to make interactive, zoomable maps using a Java package called leaflet. We will only scratch the surface of the [capabilities of Folium](https://python-visualization.github.io/folium/quickstart.html) - you can embed these maps on a website, and make all kinds of cool, interactive plots. \n","\n","These types of maps are super useful when you need to re-plot the same map over and over, for example, to update a website for weekly rainfall data, or highlight counties that have active wells drilling, etc."]},{"cell_type":"code","metadata":{"id":"2eNAGcPtNnbX"},"source":["# define a dataset to map\n","formation_to_map = df[df.Formation=='NIOBRARA'] # subset the original dataframe\n","\n","formation_to_map = formation_to_map.dropna(subset=['Latitude']) # get rid of wells with no location information\n","\n","# now create a map\n","m = folium.Map(\n","    location=[42, -105],\n","    tiles='Stamen Terrain',\n","    zoom_start=6\n",")\n","\n","# and add stuff to that map\n","for row in formation_to_map.iterrows():\n","  row_values = row[1]\n","  location = [row_values['Latitude'], row_values['Longitude']]\n","  popup = row_values['Well Name']\n","  folium.Marker(location = location, popup = popup).add_to(m)\n","\n","m"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPeXhMtQT26a"},"source":["# get some info about a particular well\n","\n","# click on a well and copy the well name, then paste it below \n","name = '31-15 MANNING'\n","\n","df[df['Well Name']==name]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g2fR10cuTW3-"},"source":["Now let's try another formation, and we will use the OpenStreetMap tiles this time. "]},{"cell_type":"code","metadata":{"id":"KjcozJY4Sz6D"},"source":["formation_to_map = df[df.Formation=='PARKMAN'] # subset the original dataframe\n","\n","formation_to_map = formation_to_map.dropna(subset=['Latitude']) # get rid of wells with no location information\n","\n","# now create a map\n","m = folium.Map(\n","    location=[45, -105],\n","    tiles='OpenStreetMap',\n","    zoom_start=6\n",")\n","\n","# and add stuff to that map\n","for row in formation_to_map.iterrows():\n","  row_values = row[1]\n","  location = [row_values['Latitude'], row_values['Longitude']]\n","  popup = row_values['Well Name']\n","  folium.Marker(location = location, popup = popup).add_to(m)\n","\n","m"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BcxpOVn_fuiS"},"source":["## Plotly\n","\n","Plotly is pretty sweet - it's even easier than folium, in my opinion. Beware, however, that plotly is a business, and they make money by getting you to sign up for their API and dashboard. So, it's really only partially open-source...\n","\n","Brendon Hall has a nice plotly notebook that he summarized in [this LinkedIn post](https://www.linkedin.com/pulse/interactive-well-maps-python-brendon-hall). Check that out, as well as the myriad of plotly tutorials online. \n","\n","### Let's look at the USGS website\n","Go check out the [Map based search](https://my.usgs.gov/crcwc/map) at the USGS CRC. Are you ready to recreate that map (and actually make it better) in about ten lines of code? \n","\n","### Let's make a quick plotly map"]},{"cell_type":"code","metadata":{"id":"Ba3UzUjKPzEq"},"source":["df_sub = df[df.State=='WY']\n","df_sub = df_sub[['Well Name','Latitude','Longitude','Formation','Thickness']]\n","df_sub = df_sub.dropna()\n","\n","fig = px.scatter_mapbox(df_sub, lat=\"Latitude\", lon=\"Longitude\",\n","                        color='Formation', \n","                        zoom=5, height=600,\n","                        hover_data={'Well Name': True,\n","                                    'Latitude': False,\n","                                    'Longitude': False,\n","                                    'Formation': True,\n","                                    'Thickness': True}\n","                        )\n","fig.update_layout(mapbox_style=\"open-street-map\")\n","fig.update_layout(margin={\"r\":200,\"t\":20,\"l\":200,\"b\":0})\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C_gvYbe7sR9I"},"source":["![Damn](https://media1.tenor.com/images/3e64ea8c3ee1147ec50376620f984792/tenor.gif?itemid=5580082)"]},{"cell_type":"code","metadata":{"id":"PpDwDOz-DRbx"},"source":["# Now you try a plotly map! \n","df_sub = df[df.State=='CO']\n","df_sub = df_sub[['Well Name','Latitude','Longitude','Formation','Thickness']]\n","df_sub = df_sub.dropna()\n","\n","fig = px.scatter_mapbox(df_sub, lat=\"Latitude\", lon=\"Longitude\",\n","                        color='Formation', \n","                        zoom=5, height=600,\n","                        hover_data={'Well Name': True,\n","                                    'Latitude': False,\n","                                    'Longitude': False,\n","                                    'Formation': True,\n","                                    'Thickness': True}\n","                        )\n","fig.update_layout(mapbox_style=\"open-street-map\")\n","fig.update_layout(margin={\"r\":200,\"t\":20,\"l\":200,\"b\":0})\n","fig.show()\n","# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GZZMJrUvDZdE"},"source":["So, see, being a fancy data scientist isn't rocket science, it's mostly just googling things. \n","![Googling is half](https://img.ifunny.co/images/072cea68327e54d5816c1a2f921f2958440586b2da0af7e9656f5255d2c7ab7b_1.jpg)\n","\n","---------\n","\n","# The End\n","![Work here is done](https://media1.tenor.com/images/168afe17abdf88b0d439c901f134a6f4/tenor.gif?itemid=4705793)"]},{"cell_type":"code","metadata":{"id":"Wge3gsWnjdKT"},"source":[],"execution_count":null,"outputs":[]}]}